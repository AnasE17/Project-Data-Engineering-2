{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "def pre_process(corpus):\n",
    "    # convert input corpus to lower case.\n",
    "    corpus = corpus.lower()\n",
    "    # collecting a list of stop words from nltk and punctuation form\n",
    "    # string class and create single array.\n",
    "    stopset = stopwords.words('english') + list(string.punctuation)\n",
    "    # remove stop words and punctuations from string.\n",
    "    # word_tokenize is used to tokenize the input corpus in word tokens.\n",
    "    corpus = \" \".join([i for i in word_tokenize(corpus) if i not in stopset])\n",
    "    # remove non-ascii characters\n",
    "    corpus = unidecode(corpus)\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# sentence pair\n",
    "#corpus = ['A girl is styling her hair.']\n",
    "#corpus2 = ['I do not like the hair of this girl']\n",
    "\n",
    "#for c in range(len(corpus)):\n",
    "#    corpus[c] = pre_process(corpus[c])\n",
    "\n",
    "#for c in range(len(corpus2)):\n",
    " #   corpus2[c] = pre_process(corpus2[c])\n",
    "  \n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "#tfidf_vectorizer.fit(corpus)\n",
    "#feature_vectors = tfidf_vectorizer.transform(corpus)\n",
    "#tfidf_vectorizer2 = TfidfVectorizer(ngram_range=(1,2))\n",
    "#tfidf_vectorizer2.fit(corpus2)\n",
    "#feature_vectors2 = tfidf_vectorizer.transform(corpus2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=common_texts, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "word_emb_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#import itertools\n",
    "\n",
    "#def map_word_frequency(document):\n",
    "#    return Counter(itertools.chain(*document))\n",
    "    \n",
    "#def get_sif_feature_vectors(sentence1, sentence2, word_emb_model=word_emb_model):\n",
    "#    sentence1 = [token for token in sentence1.split() if token in word_emb_model.wv.vocab]\n",
    "#    sentence2 = [token for token in sentence2.split() if token in word_emb_model.wv.vocab]\n",
    "#    word_counts = map_word_frequency((sentence1 + sentence2))\n",
    "#    embedding_size = 300 # size of vectore in word embeddings\n",
    "#    a = 0.001\n",
    "#    sentence_set=[]\n",
    "#    for sentence in [sentence1, sentence2]:\n",
    "#        vs = np.zeros(embedding_size)\n",
    "#        sentence_length = len(sentence)\n",
    "#        for word in sentence:\n",
    "#            a_value = a / (a + word_counts[word]) # smooth inverse frequency, SIF\n",
    "#            vs = np.add(vs, np.multiply(a_value, word_emb_model.wv[word])) # vs += sif * word_vector\n",
    "#        vs = np.divide(vs, sentence_length) # weighted average\n",
    "#        sentence_set.append(vs)\n",
    "#    return sentence_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_cosine_similarity(feature_vectors, feature_vectors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"text\", \n",
    "                     keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Sep 23</td>\n",
       "      <td>779503099492831232</td>\n",
       "      <td>/realDonaldTrump/status/779503099492831233</td>\n",
       "      <td>False</td>\n",
       "      <td>Crooked Hillary's bad judgement forced her to ...</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    date                  id  \\\n",
       "77          77  Sep 23  779503099492831232   \n",
       "\n",
       "                                          link  retweet  \\\n",
       "77  /realDonaldTrump/status/779503099492831233    False   \n",
       "\n",
       "                                                 text       author  \n",
       "77  Crooked Hillary's bad judgement forced her to ...  DonaldTrump  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dftest = df.loc[lambda df: df['Unnamed: 0'] == 77]\n",
    "#dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12979"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftest1 = df.loc[lambda df: df['text'] == 'AMERICA FIRST!']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va calculer la similarity avec tous les tweet du dataset \n",
    "#On va les insérer dans une liste (par id ou index pour les retrouver )\n",
    "#On va trier la liste (algo de tri)\n",
    "#On va prendre les 20 valeurs les plus élevées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Calculons la similarité d'un string avec tous les tweet \n",
    "l = []\n",
    "\n",
    "corpus = ['I love america']\n",
    "\n",
    "for c in range(len(corpus)):\n",
    "    corpus[c] = pre_process(corpus[c])\n",
    "\n",
    "#for c in range(len(corpus2)):\n",
    "    #corpus2[c] = pre_process(corpus2[c])\n",
    "    \n",
    "#tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "#tfidf_vectorizer.fit(corpus)\n",
    "#feature_vectors1 = tfidf_vectorizer.transform(corpus)\n",
    "\n",
    "\n",
    "\n",
    "for i in df['Unnamed: 0']:\n",
    "    l1=[]\n",
    "    df1 = df.loc[lambda df: df['Unnamed: 0'] == i]\n",
    "    #a = str(df1['text'])\n",
    "    a1 = df1['text']\n",
    "    a2 = list(a1)\n",
    "    a = a2[0]\n",
    "    l1.append(a)\n",
    "    l1[0] = pre_process(l1[0])\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    tfidf_vectorizer.fit(l1)\n",
    "    feature_vectors = tfidf_vectorizer.transform(l1)\n",
    "    feature_vectors1 = tfidf_vectorizer.transform(corpus)\n",
    "    l.append(get_cosine_similarity(feature_vectors, feature_vectors1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[]\n",
    "for i in range (0,len(l)):\n",
    "    if l[i] !=0:\n",
    "        l2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7 = df.loc[lambda df: df['Unnamed: 0'] == 16660]\n",
    "#df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df8 = df.loc[lambda df: df['Unnamed: 0'] == 14600]\n",
    "#df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in l2:\n",
    "    d[i] = l[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {k: v for k, v in sorted(d.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Whether you realize it or not, your brand can be many times more valuable than your business.” – Midas Touch\n",
      "Remember, as a senator, Obama did not vote for increasing the debt ceiling http://bit.ly/f7yQrU   I guess things change when President?!\n",
      "I've just started blocking out some of the repetitive and boring (& dumb) haters and losers. They are a waste of time and energy!\n",
      "AMERICA FIRST!\n",
      "Big time in U.S. today - MAKE AMERICA GREAT AGAIN! Politicians are all talk and no action - they can never bring us back.\n",
      "MAKE AMERICA GREAT AGAIN! MAKE AMERICA SAFE AGAIN!\n",
      " \n",
      "Order signed copy of CRIPPLED AMERICA & have opportunity to submit question for my live streaming book signing 12/3http://livesigning.com/trump/welcome \n",
      "I am a handwriting analyst. Jack Lew’s handwriting shows, while strange, that he is very secretive—not necessarily a bad thing.\n",
      " \n",
      "\"@GZervs: All I want for my birthday is for @realDonaldTrump to wish me a happy birthday!\"  Happy birthday.\n",
      "Talent is cheaper than table salt. What separates the talented individual from the successful one is a lot of hard work.\n",
      " -- Stephen King\n",
      "Via @WDesMoinesPatch by @DerekJ3031: “@ShawnJohnson on @ApprenticeNBC”\n",
      "http://patch.com/iowa/urbandale/shawn-johnson-celebrity-apprentice-0 …\n",
      "\"@RSan: Donald Trump's Polling Looks too Good to Be True.\n",
      "Via @BreitbartNews by @mboyle1: \"TRUMP: OBAMA SHOULDN’T ATTACK AMERICANS OVERSEAS, HILLARY’S EMAIL WAS ‘CRIMINAL\"http://www.breitbart.com/big-government/2015/07/28/exclusive-trump-obama-shouldnt-attack-americans-overseas-hillarys-email-was-criminal-smears-against-me-vicious-but-ineffective/ …\n",
      "\"@CMHeel: @realDonaldTrump do like Mexico?\"   Yes, but they make a fortune off the U.S.  Their leaders are far better negotiators than ours.\n",
      "\"@HappiiKarii: @realDonaldTrump why didn't you run for this term?\"  I should have, I would have won!\n",
      "Now Syria is bombing Iraq and Secy. Kerry, after we blew the hell out of the place, says please don't do that. Syria is a front for Iran.\n",
      "Entrepreneurs: See yourself as victorious. Look at the solution, not the problem. Keep your focus positive.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    df3 = df.loc[lambda df: df['Unnamed: 0'] == list(d1)[-i]]\n",
    "    a = list(df3['text'])\n",
    "    if not a:\n",
    "        print(\" \")\n",
    "    else:\n",
    "        print(a[0])\n",
    "    #a = str(df3['text']+df3['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>5940</td>\n",
       "      <td>12 Nov 2014</td>\n",
       "      <td>532633328676241408</td>\n",
       "      <td>/realDonaldTrump/status/532633328676241408</td>\n",
       "      <td>False</td>\n",
       "      <td>Entrepreneurs: See yourself as victorious. Loo...</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         date                  id  \\\n",
       "5940        5940  12 Nov 2014  532633328676241408   \n",
       "\n",
       "                                            link  retweet  \\\n",
       "5940  /realDonaldTrump/status/532633328676241408    False   \n",
       "\n",
       "                                                   text       author  \n",
       "5940  Entrepreneurs: See yourself as victorious. Loo...  DonaldTrump  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Entrepreneurs: See yourself as victorious. Look at the solution, not the problem. Keep your focus positive.'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = df3['text']\n",
    "#s1 = s.values\n",
    "#s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = df3['text']\n",
    "#type(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
